# apps/backend/services/db.py
from __future__ import annotations
import sqlite3
from pathlib import Path
from typing import Optional, Dict, List
from datetime import datetime, timedelta

# .../apps/backend/services/db.py -> data/gymgpt.db
DB_DIR = (Path(__file__).resolve().parent / ".." / ".." / "data").resolve()
DB_DIR.mkdir(parents=True, exist_ok=True)
DB_PATH = DB_DIR / "gymgpt.db"

def _conn() -> sqlite3.Connection:
    conn = sqlite3.connect(DB_PATH, check_same_thread=False)
    conn.row_factory = sqlite3.Row
    # light concurrency safety + durability for dev
    conn.execute("PRAGMA journal_mode = WAL;")
    conn.execute("PRAGMA foreign_keys = ON;")
    return conn

def init_db() -> None:
    with _conn() as conn:
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS logs(
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL,
                reps INTEGER NOT NULL,
                weight_kg REAL NOT NULL,
                rir INTEGER NOT NULL,
                focus TEXT,
                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
            );
            """
        )
        conn.execute(
            "CREATE INDEX IF NOT EXISTS idx_logs_name_time ON logs(name, timestamp);"
        )
        conn.execute(
            """
            CREATE TABLE IF NOT EXISTS plans(
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                title TEXT NOT NULL,
                input_json TEXT NOT NULL,
                output_json TEXT NOT NULL
            );
            """
        )
        conn.execute(
            "CREATE INDEX IF NOT EXISTS idx_plans_created_at ON plans(created_at);"
        )

def add_log(
    name: str,
    reps: int,
    weight_kg: float,
    rir: int,
    focus: Optional[str] = None,
) -> Dict:
    with _conn() as conn:
        cur = conn.execute(
            "INSERT INTO logs(name, reps, weight_kg, rir, focus) VALUES (?,?,?,?,?)",
            (name, reps, weight_kg, rir, focus),
        )
        log_id = cur.lastrowid
        row = conn.execute(
            "SELECT id, name, reps, weight_kg, rir, focus, timestamp FROM logs WHERE id = ?",
            (log_id,),
        ).fetchone()
        return dict(row)

def get_logs(focus: Optional[str] = None) -> List[Dict]:
    with _conn() as conn:
        if focus:
            cur = conn.execute(
                """
                SELECT id, name, reps, weight_kg, rir, focus, timestamp
                FROM logs
                WHERE focus = ?
                ORDER BY id DESC
                """,
                (focus,),
            )
        else:
            cur = conn.execute(
                """
                SELECT id, name, reps, weight_kg, rir, focus, timestamp
                FROM logs
                ORDER BY id DESC
                """
            )
        return [dict(r) for r in cur.fetchall()]

def get_recent_sets_map(days: int = 14) -> Dict[str, List[Dict]]:
    """
    Returns: { exercise_name: [ {reps, weight_kg, rir, timestamp}, ... ] }
    Only entries within last `days`.
    """
    since = (datetime.utcnow() - timedelta(days=days)).strftime("%Y-%m-%d %H:%M:%S")
    out: Dict[str, List[Dict]] = {}
    with _conn() as conn:
        cur = conn.execute(
            """
            SELECT name, reps, weight_kg, rir, timestamp
            FROM logs
            WHERE timestamp >= ?
            ORDER BY timestamp DESC
            """,
            (since,),
        )
        for r in cur.fetchall():
            d = dict(r)
            out.setdefault(d["name"], []).append(
                {
                    "reps": d["reps"],
                    "weight_kg": d["weight_kg"],
                    "rir": d["rir"],
                    "timestamp": d["timestamp"],
                }
            )
    return out

def get_latest_by_exercise(limit_per_exercise: int = 3) -> Dict[str, List[Dict]]:
    """
    Top-N latest sets for each exercise (useful if you don't want a date window).
    """
    with _conn() as conn:
        # SQLite doesn't have DISTINCT ON; emulate via window function in newer versions
        # fallback: simple group in Python
        cur = conn.execute(
            """
            SELECT name, reps, weight_kg, rir, timestamp
            FROM logs
            ORDER BY name ASC, timestamp DESC
            """
        )
        tmp: Dict[str, List[Dict]] = {}
        for r in cur.fetchall():
            d = dict(r)
            bucket = tmp.setdefault(d["name"], [])
            if len(bucket) < limit_per_exercise:
                bucket.append(
                    {
                        "reps": d["reps"],
                        "weight_kg": d["weight_kg"],
                        "rir": d["rir"],
                        "timestamp": d["timestamp"],
                    }
                )
        return tmp
def add_plan(title: str, input_json: str, output_json: str) -> Dict:
    with _conn() as conn:
        cur = conn.execute(
            "INSERT INTO plans(title, input_json, output_json) VALUES (?,?,?)",
            (title, input_json, output_json),
        )
        plan_id = cur.lastrowid
        row = conn.execute(
            "SELECT id, created_at, title, input_json, output_json FROM plans WHERE id = ?",
            (plan_id,),
        ).fetchone()
        return dict(row)

def list_plans(limit: int = 20, offset: int = 0) -> List[Dict]:
    with _conn() as conn:
        cur = conn.execute(
            """
            SELECT id, created_at, title
            FROM plans
            ORDER BY id DESC
            LIMIT ? OFFSET ?
            """,
            (limit, offset),
        )
        return [dict(r) for r in cur.fetchall()]

def get_plan(plan_id: int) -> Optional[Dict]:
    with _conn() as conn:
        row = conn.execute(
            """
            SELECT id, created_at, title, input_json, output_json
            FROM plans
            WHERE id = ?
            """,
            (plan_id,),
        ).fetchone()
        return dict(row) if row else None

